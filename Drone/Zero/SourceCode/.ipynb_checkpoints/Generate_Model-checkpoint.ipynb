{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1 is preprocessed\n",
      "subject 2 is preprocessed\n",
      "subject 3 is preprocessed\n",
      "subject 4 is preprocessed\n",
      "subject 5 is preprocessed\n",
      "subject 6 is preprocessed\n",
      "subject 7 is preprocessed\n",
      "subject 8 is preprocessed\n",
      "subject 9 is preprocessed\n",
      "subject 10 is preprocessed\n",
      "subject 11 is preprocessed\n",
      "subject 12 is preprocessed\n",
      "subject 13 is preprocessed\n",
      "subject 14 is preprocessed\n",
      "subject 15 is preprocessed\n",
      "subject 16 is preprocessed\n",
      "subject 17 is preprocessed\n",
      "subject 18 is preprocessed\n",
      "subject 19 is preprocessed\n",
      "subject 20 is preprocessed\n",
      "subject 21 is preprocessed\n",
      "subject 22 is preprocessed\n",
      "subject 23 is preprocessed\n",
      "subject 24 is preprocessed\n",
      "subject 25 is preprocessed\n",
      "subject 26 is preprocessed\n",
      "subject 27 is preprocessed\n",
      "subject 28 is preprocessed\n",
      "subject 29 is preprocessed\n",
      "subject 30 is preprocessed\n",
      "subject 31 is preprocessed\n",
      "subject 32 is preprocessed\n",
      "subject 33 is preprocessed\n",
      "subject 34 is preprocessed\n",
      "subject 35 is preprocessed\n",
      "subject 36 is preprocessed\n",
      "subject 37 is preprocessed\n",
      "subject 38 is preprocessed\n",
      "subject 39 is preprocessed\n",
      "subject 40 is preprocessed\n",
      "subject 41 is preprocessed\n",
      "subject 42 is preprocessed\n",
      "subject 43 is preprocessed\n",
      "subject 44 is preprocessed\n",
      "subject 45 is preprocessed\n",
      "subject 46 is preprocessed\n",
      "subject 47 is preprocessed\n",
      "subject 48 is preprocessed\n",
      "subject 49 is preprocessed\n",
      "subject 50 is preprocessed\n",
      "subject 51 is preprocessed\n",
      "subject 52 is preprocessed\n",
      "subject 53 is preprocessed\n",
      "subject 54 is preprocessed\n",
      "subject 55 is preprocessed\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Conv2DCustomBackpropInputOp only supports NHWC.\n\t [[node gradient_tape/sequential_3/conv2d_6/Conv2DBackpropInput (defined at <ipython-input-7-c5150f859fbb>:178) ]] [Op:__inference_train_function_2322]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c5150f859fbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c5150f859fbb>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mfittedModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalLabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\user\\\\Desktop\\\\Drone\\\\Zero\\\\Model\\\\ZeroCNN_7CH(0.23-30, 0.0-1.0).h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Conv2DCustomBackpropInputOp only supports NHWC.\n\t [[node gradient_tape/sequential_3/conv2d_6/Conv2DBackpropInput (defined at <ipython-input-7-c5150f859fbb>:178) ]] [Op:__inference_train_function_2322]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "## DataProcessing and model generation process\n",
    "import hdf5storage\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, AveragePooling2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs \n",
    "\n",
    "def Balancing_DataSet(Epochs, size):\n",
    "    Epochs_New = np.zeros((size, Epochs.shape[1], Epochs.shape[2]))\n",
    "    \n",
    "    index = np.random.choice(Epochs.shape[0], size = size, replace = False)\n",
    "    \n",
    "    Epochs_New = Epochs[index, :, :]\n",
    "    \n",
    "    return Epochs_New\n",
    "\n",
    "def Epoching(eegData, stimsT, samplingFreq, channelNum, epochSampleNum, offset, baseline):\n",
    "        Time_after = np.add(stimsT,offset).astype(int)\n",
    "        Time_base = np.add(stimsT,baseline).astype(int)\n",
    "        Num = stimsT.shape[1]\n",
    "        Epochs = np.zeros((Num, channelNum, epochSampleNum))\n",
    "        for j in range(Num):\n",
    "            Epochs[j, :, :] = eegData[:,Time_after[0][j]:Time_after[0][j] + epochSampleNum]\n",
    "            \n",
    "        return [Epochs,Num]\n",
    "\n",
    "def DownsamplingEpoch(EpochsT, EpochsN, downsampleRate):\n",
    "        num = np.floor(EpochsT.shape[2] / downsampleRate).astype(int)\n",
    "        DownsampledT = np.zeros((EpochsT.shape[0],EpochsT.shape[1],num))\n",
    "        DownsampledN = np.zeros((EpochsN.shape[0],EpochsN.shape[1],num))\n",
    "        for i in range(num):\n",
    "            for j in range(EpochsT.shape[1]):\n",
    "                for k in range(EpochsT.shape[0]):\n",
    "                    DownsampledT[k,j,i] = np.mean(EpochsT[k,j,i*downsampleRate:(i+1)*downsampleRate],dtype=np.float64)\n",
    "                for l in range(EpochsN.shape[0]):\n",
    "                    DownsampledN[l,j,i] = np.mean(EpochsN[l,j,i*downsampleRate:(i+1)*downsampleRate],dtype=np.float64)\n",
    "        return [DownsampledT, DownsampledN, num]\n",
    "\n",
    "def Make_Average_Component(EpochsT, NumT, EpochsN, NumN, channelNum, epochSampleNum, componentNum):\n",
    "    EpochsT = Standardization(EpochsT)\n",
    "    EpochsN = Standardization(EpochsN)\n",
    "    \n",
    "    NumT_Aver = NumT-componentNum\n",
    "    NumN_Aver = NumN-componentNum\n",
    "    \n",
    "    EpochsT_Aver = np.zeros((NumT_Aver, channelNum, epochSampleNum))\n",
    "    EpochsN_Aver = np.zeros((NumN_Aver, channelNum, epochSampleNum))\n",
    "    for i in range(NumT_Aver):\n",
    "        EpochsT_Aver[i, :, :] = np.mean(EpochsT[i:i+componentNum, :, :], axis=0)\n",
    "    for j in range(NumN_Aver):\n",
    "        EpochsN_Aver[j, :, :] = np.mean(EpochsN[j:j+componentNum, :, :], axis=0)\n",
    "        \n",
    "    return [EpochsT_Aver, NumT_Aver, EpochsN_Aver, NumN_Aver]\n",
    "    \n",
    "def GenerateP300Data(filename):\n",
    "        channelNum = 7\n",
    "        epochSampleNum = 256\n",
    "        target = np.zeros((260,channelNum,epochSampleNum))\n",
    "        nontarget = np.zeros((260,channelNum,epochSampleNum))\n",
    "        for i in np.arange(1,3):\n",
    "            if (i==2):\n",
    "                filename = filename + '_2'\n",
    "            mat = hdf5storage.loadmat(filename)\n",
    "            eegData = mat['eegData']\n",
    "            samplingFreq = mat['samplingFreq'][0,0]\n",
    "            stimsN = mat['stimsN']\n",
    "            stimsT = mat['stimsT']\n",
    "            sampleNum = eegData.shape[1]\n",
    "            channelIndex = [18, 30, 12, 11, 19, 10, 15]\n",
    "            \n",
    "            # vr300 7 channel\n",
    "            # [P4, Fz, Pz, P3, PO8, PO7, Oz]\n",
    "            # [19, 31, 13, 12, 20, 11, 16]\n",
    "            \n",
    "            eegData = eegData[channelIndex]\n",
    "        \n",
    "            ## Preprocessing process\n",
    "        \n",
    "            #Bandpass Filter\n",
    "            eegData = butter_bandpass_filter(eegData, 0.23, 30, samplingFreq, 4)\n",
    "        \n",
    "            #Epoching\n",
    "            epochSampleNum = int(np.floor(1.0 * samplingFreq))\n",
    "            offset = int(np.floor(0.0 * samplingFreq))\n",
    "            baseline = int(np.floor(1.0 * samplingFreq))\n",
    "            [EpochsT, NumT] = Epoching(eegData, stimsT, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            [EpochsN, NumN] = Epoching(eegData, stimsN, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            \n",
    "            NumN = NumT\n",
    "            EpochsN = Balancing_DataSet(EpochsN, NumN)\n",
    "            \n",
    "            #Downsampling\n",
    "            downsampleRate = 2\n",
    "            samplingFreq = samplingFreq / 2\n",
    "            [EpochsT,EpochsN,epochSampleNum] = DownsamplingEpoch(EpochsT, EpochsN, downsampleRate)\n",
    "            \n",
    "            [EpochsT, NumT_Aver, EpochsN, NumN_Aver] = Make_Average_Component(EpochsT, NumT, EpochsN, NumN, channelNum, epochSampleNum, 20)\n",
    "            \n",
    "            # # plotEEGdata(eegData, channelNum)\n",
    "            target[130*(i-1):130*i,:,:] = EpochsT\n",
    "            nontarget[130*(i-1):130*i,:,:] = EpochsN\n",
    "        \n",
    "        return [target, nontarget]\n",
    "\n",
    "def main():\n",
    "        root = 'C:\\\\Users\\\\user\\\\Desktop\\\\P300_biosemi_55\\\\S'\n",
    "        filename = ''\n",
    "        channelNum = 7\n",
    "        epochSampleNum = 256\n",
    "        epochNum = 260\n",
    "        alltarget = np.zeros((epochNum*55,channelNum,epochSampleNum))\n",
    "        allnontarget = np.zeros((epochNum*55,channelNum,epochSampleNum))\n",
    "        for i in np.arange(1,56):\n",
    "            if(i<10):\n",
    "                filename = root + '0' + str(i)\n",
    "            else:\n",
    "                filename = root + str(i)\n",
    "            [alltarget[epochNum*(i-1):epochNum*i,:,:],allnontarget[epochNum*(i-1):epochNum*i,:,:]] = GenerateP300Data(filename)\n",
    "            print(\"subject {0} is preprocessed\".format(str(i)))\n",
    "        \n",
    "        \n",
    "        trainingData = np.concatenate((alltarget, allnontarget))\n",
    "#         np.savetxt('C:\\\\Users\\\\user\\\\Desktop\\\\trainingData.out', trainingData, delimiter=',')\n",
    "        trainingData = np.reshape(trainingData,((epochNum*2)*55,1,channelNum,epochSampleNum));\n",
    "        label = np.concatenate((np.ones((epochNum*55,1)).astype(int),np.zeros((epochNum*55,1)).astype(int))).ravel()\n",
    "        label = np_utils.to_categorical(label, 2);\n",
    "        \n",
    "        ##Generating CNN model\n",
    "        model = Sequential();\n",
    "        #model.add(AveragePooling2D(pool_size=(1, 4), strides=(1,4))) # this was added\n",
    "        model.add(Conv2D(epochSampleNum, kernel_size=(1, 25),data_format='channels_first',input_shape=(1, channelNum, epochSampleNum)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(epochSampleNum, (channelNum, 1),data_format='channels_first')) \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(2))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        #model = multi_gpu_model(model, gpus=2);\n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['categorical_accuracy']);\n",
    "        \n",
    "        data = trainingData;\n",
    "        randIdx = np.random.permutation(55*(epochNum*2));\n",
    "        trainIdx = randIdx[0:int((epochNum*2)*55*0.95)];\n",
    "        valIdx = randIdx[int((epochNum*2)*55*0.95):55*(epochNum*2)];\n",
    "        \n",
    "        trainData = data[trainIdx,:,:,:];\n",
    "        trainLabel = label[trainIdx];\n",
    "        valData = data[valIdx,:,:,:];\n",
    "        valLabel = label[valIdx];\n",
    "        \n",
    "        early_stopping = EarlyStopping(patience = 3);\n",
    "        \n",
    "        fittedModel = model.fit(trainData, trainLabel, epochs=10, validation_data=(valData, valLabel), callbacks=[early_stopping]);\n",
    "        \n",
    "        model.save('C:\\\\Users\\\\user\\\\Desktop\\\\Drone\\\\Zero\\\\Model\\\\ZeroCNN_7CH(0.23-30, 0.0-1.0).h5')\n",
    "        model.save_weights('C:\\\\Users\\\\user\\\\Desktop\\\\Drone\\\\Zero\\\\Model\\\\ZeroCNN_7CH_Weight(0.23-30, 0.0-1.0).h5')\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip instsall keras\n",
    "pip install tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
